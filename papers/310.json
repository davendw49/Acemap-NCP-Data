{"date": "2020/02/14", "journal": "medrxiv", "authors": "Shuai Wang, Bo Kang, Jinlu Ma, Xianjun Zeng, Mingming Xiao, Jia Guo, Mengjiao Cai, Jingyi Yang, Yaodong Li, Xiangfei Meng, Bo Xu", "title": "A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19)", "type": "preprint article", "abstract": "Tianjin 300006, China", "text": "Bo Xu, MD, PhDThe authors have declared no competing interest.The outbreak of Severe Acute Respiratory Syndrome Coronavirus 2(SARS-COV-2) has caused approximately 64,000 cases of Corona Virus Disease(COVID-19) in China so far, with that number continuing to grow. To control thespread of the disease, screening large numbers of suspected cases for appropriatequarantine and treatment measures is a priority. Viral nucleic acid testing based onspecimens from the lower respiratory tract is the diagnostic gold standard. However,the availability and quality of laboratory testing in the infected region presents achallenge\uff0cso alternative diagnostic methods are urgently needed to combat thedisease. Based on COVID-19 radiographical changes in CT images, wehypothesized that Artificial Intelligence\u2019s deep learning methods might be able toextract COVID-19\u2019s specific graphical features and provide a clinical diagnosisahead of the pathogenic test, thus saving critical time for disease control. To testthis possibility, we collected 453 CT images of pathogen-confirmed COVID-19cases along with previously diagnosed with typical viral pneumonia. 217 imageswere used as the training set and the inception migration-learning model was usedto establish the algorithm. The internal validation achieved a total accuracy of 82.9%with specificity of 80.5% and sensitivity of 84%. The external testing datasetshowed a total accuracy of 73.1% with specificity of 67% and sensitivity of 74%.These results indicate the great value of using the deep learning method to extractradiological graphical features for COVID-19 diagnosis.        The outbreak of atypical and person-to-person transmissible pneumoniacaused by the severe acute respiratory syndrome coronavirus 2        According to the WHO, 16-21% of people with the virus in China havebecome severely ill with a 2-3% mortality rate. With the most recent estimatedviral reproduction number (R0), the average number of other people that aninfected individual will transmit the virus to in a completely non-immunepopulation, stands at about 3.77 [1], indicating that a rapid spread of thedisease is imminent. Therefore, it is crucial to identify infected individuals asearly as possible for quarantine and treatment procedures. The diagnosis ofCOVID-19 relies on the following criteria: clinical symptoms, epidemiologicalhistory and positive CT images as well as positive pathogenic testing. Theclinical characteristics of COVID-19 include respiratory symptoms, fever,cough, dyspna, and viral pneumonia [2-5], however, these symptoms arenonspecific, as thereare isolated caseswhere, for example, inanasymptomatic infected family a chest CT scan revealed pneumonia and thepathogenic test for the virus came back positive.Once someone is identified as a PUI (person under investigation), lowerrespiratory specimens, such as bronchoalveolar lavage, tracheal aspirate orsputum, will be collected for pathogenic testing. This laboratory technology isbased on real-time RT-PCR and sequencing of nucleic acid from the virus [6,7]. Since the beginning of the outbreak, the efficiency of nucleic acid testinghas been dependent on several rate-limiting factors, including availability andquantity of the testing kits in the affected area. More importantly, the quality,stability and reproducibility of the detection kits are questionable. The impact ofmethodology, disease development stages, specimen collection methods,nucleic acid extractionmethods and the amplification systemare alldeterminant factors for the accuracy of test results. Conservative estimates ofthe detection rate of nucleic acid are low (between 30-50%), and tests need tobe repeated several times in many cases before they can be confirmed.Radiological imaging is also a major diagnostic tool for COVID-19. Themajority of COVID-19 cases have similar features on CT images includingground-glass opacities in the early stage and pulmonary consolidation in thelate stage. There is also sometimes a rounded morphology and a peripherallung distribution [5, 8]. Although typical CT images may help early screening ofsuspected cases, the images of various viral pneumonias are similar and theyoverlap with other infectious and inflammatory lung diseases. Therefore, it isdifficult for radiologists to distinguish COVID-19 from other viral pneumonias.Artificial Intelligence involving medical imaging deep-learning systems hasbeen developed in image feature extraction, including shape and spatialrelation features. Specifically, Convolutional Neural Network (CNN) has beenproven in feature extraction and learning. CNN was used to enhance low-lightimages from high-speed video endoscopy with the limited training data beingjust 55 videos [9]. Also, CNN has been applied to identify the nature ofpulmonary nodules via CT images, the diagnosis of pediatric pneumonia viachest X-ray images, automated precising and labeling of polyps duringcolonoscopic videos, cystoscopic image recognition extraction from videos[10-13].There are a number of features for identifying viral pathogens on the basisof imaging patterns, which are associated with their specific pathogenesis [14].The hallmarks of COVID-19 are bilateral distribution of patchy shadows andground glass opacity [2]. Based on this, we believed that CNN might help usidentify unique features that might be difficult for visual recognition. To test thisnotion, we retrospectively enrolled 453 CT images of pathogen-confirmedCOVID-19 cases along with previously diagnosed typical viral pneumonia. Wetrained 217 images using the inception migration-learning model in order toestablish the algorithm. We achieved a total accuracy of 83% with specificity of80.5% and sensitivity of 84% for validation. The external testing showed a totalaccuracy of 73% with specificity of 67% and sensitivity of 74%. Theseobservations demonstrate the proof-of-principle using the deep learningmethod to extract radiological graphical features for COVID-19 diagnosis.We retrospectively collected CT images from 99 patients, in which the cohortincludes 55 cases of typical viral pneumonia and the other 44 cases from threedifferent hospitals with confirmed nucleic acid testing of SARS-COV-2. Thehospitals providing the images were Xi\u2019an Jiaotong University First AffiliatedHospital, Nanchang University First Hospital and Xi\u2019An No.8 Hospital of Xi\u2019AnMedical College. All CT images were de-identified before sending for analysis.This study is in compliance with the Institutional Review Board of eachparticipating institutes. Informed consent was exempted by the IRB because ofthe retrospective nature of this study.Our systematic pipeline for the prediction architecture is depicted in Figure 1.The architecture consists of three main processes. 1) Randomly selection ofROIs; 2) Training of the CNN model to extract features; 3) Classification modeltraining of fully connected network and prediction of multiple classifiers.computed tomography scan, we randomly selected ROIs and used theCT images were recorded by video camera, which approximately 1*1 in-planeresolution. In order to reduce the computation complexity, and based on thesigns characteristic of pneumonia, regions of interest (ROI) were extractedfrom CT images. For a ROI, it is sized approximately from 395*223 to 636*533pixels. We picked 195 ROIs from 44 COVID-19 positive pneumonia patientsand 258 ROIs from 50 COVID-19 negative patients. We built a transferlearning neural network based on Inception network. The entire neural networkcan be roughly divided into two parts: the first part uses a pre-trained inceptionnetwork to convert image data into one-dimensional feature vectors, and thesecond part uses a fully connected network and the main role is forclassification prediction. We randomly take 2-3 pictures from each case to forma training dataset. The number of various types of pictures in the training set isapproximately equal, with a total number of 236. The remaining CT pictures ofeach case were used for validation. The model training is iterated 15,000 timeswith a step size of 0.01. In total, 236 ROIs were used to train the model and217 ROI were extracted for validation.We modified the typical Inception network, and fine-tuned the modifiedInception (M-Inception) model with pre-trained weights. During the trainingphase, the original Inception part was not trained, and we only trained themodified part. The architecture of M-Inception is shown in Table 1. Thedifference between Inception and M-Inception in classification lies in the lastfully-connected layers. We reduced the dimension of features before it wassent to the final classification layer. The training dataset made up of all thosepatches aforementioned. The Inception network is shown in Table1.poolonvconvconvpoollinearsoftmaxFc1Fc2conv padded 3\u00d73/1Modifiedpart3\u00d73/23\u00d73/13\u00d73/23\u00d73/13\u00d73/23\u00d73/18x8logitsclassifierAfter generating the features, the final step is to classify the pneumonia basedon those features. Ensembling of classifiers was used to improve theclassification accuracy. In this study, we combined Decision tree and Adaboostto produce the performance.We compared the classification performance using Accuracy, Sensitivity,Specificity, Area Under Curve (AUC), Positive predictive value (PPV), Negativepredictive value (NPV), F1 score and Youden Index. TP and TN represent thenumber of true positive and true negative samples. FP and FN mean thenumber of false positive false negative samples. Sensitivity measures the ratioof positives that are correctly discriminated. Specificity measures the ratio ofnegatives that are correctly discriminated. AUC is an index to measure theperformance of the classifier. NPV was used to evaluate the algorithm forscreening and PPV was the probability of getting a disease when thediagnostic index is positive. Youden Index was the determining exponent of theoptimal bound. F1 score was a measure of the accuracy of a binary model.Additionally, performance was evaluated with F-measure (F1) to compare thesimilarity and diversity of performance. F1=2gPregSenPre+SenIn order to develop a deep learning algorithm for the identification of viralpneumonia images, we retrospectively enrolled 99 patients, in which thecohort includes 55 cases of typical viral pneumonia that were diagnosedpreviously before theCOVID-19 negative in the cohort. The other 44 cases are from the threehospitalswith confirmed nucleic acid testing of SARS-COV-2, termedCOVID-19 positive.Two radiologists were asked to review the images andsketched a total of 453 representative images (258 for COVID-19 negative and195 for COVID-19 positive) for analysis. These images were randomly dividedinto a training set and a validation set. First, we randomly selected two or threeimages from all of the patients\u2019 images for training and the remaining imageswere used for internal validation. The model training has been iterated for15,000 times with a step size of 0.01. The training loss curve is shown inTo test the stability and generalization of the model, we also randomlyselected 237 images (118 images from COVID-19 negative and 119 imagesfrom COVID-19 positive) to construct the model.The DL algorithm yielded an AUC of 0.90 (95% CI, 0.86 to 0.94 ) on theinternal validation and 0.78 (95% CI, 0.71 to 0.84) on the external validation.The AUC was shown in Figure 3. Using the maximized Youdenindex thresholdprobability, the sensitivity was 80.5% and 67.1%, specificity 84.2% and 76.4%,theaccuracy was 82.9% and 73.1%, the negative prediction value was 0.88and 0.81, the Youden index was 0.69 and 0.44 and F1 score was 0.77 and0.64 on the internal and external datasets, respectively (Table 2). Thealgorithm was executed at a rate of xxxx seconds per case on the graphicsprocessing unit.identification for deep learning (Inception) algorithm.AUC\uff0895%CI\uff09Accuracy, %SensitivitySpecificityPPVNPVF1 scoreYoden index82.90.810.840.730.880.770.69Timely diagnosis and triaging of PUIs are crucial for the control ofemerging infectious diseases such as the current COVID-19. Due to thelimitation of nucleic acid -based laboratory testing, there is an urgent need tolook for fast alternative methods that can be used by front-line health carepersonal for quickly and accurately diagnosing the disease. In the presentstudy, we have developed an AI program by analyzing representative CTimages using a deep learning method. This is a retrospective, multicohort,diagnostic study. We constructed an Inception migration neuro network thatachieved 82.9% accuracy. Moreover, the high performance of the deeplearning model we developed in this study was tested using external sampleswith 73% accuracy. These findings have demonstrated the proof of principlethat deep learning can extract CT image features of COVID-19 for diagnosticpurposes. Further developing this systemcan significantly shorten thediagnosis time for disease control. In addition, it can reduce the diagnosticworkload of physicians in the field. Our study represents the first study to applyartificial intelligence technologies to CT images for effectively screening forCOVID-19.The gold standard for COVID-19 diagnosis has been nucleic acid baseddetection for the existence of specific sequences of the SARS-COV-2 gene.While we still value the importance of nucleic acid detection in the diagnosisof the viral infection, we must also note that the significantly high number offalse negatives due to several factors such as methodological disadvantages,disease stages, and methods for specimen collection might delay diagnosisand disease control. Recent data have suggested that the accuracy of nucleicacid testing is only about 30-50%. Using CT imaging feature extraction, weare able to achieve above 83% accuracy, significantly outplaying nucleic acidtesting. In addition, this method is non-invasive with minimal cost. Althoughwe are satisfied with the initial results, we believe that with more CT imagesincluded in the training, we will achieve higher accuracy. Therefore, furtheroptimizing and testing this system is warranted. To achieve this, we havegenerated a webpage that licensed healthcare personnel can access toupload CT images for testing. The webpage information is as following:There are some limitations to our study. CT images present a difficultclassification task due to the relatively large number of variable objects,specifically the imaged areas outside the lungs that are irrelevant to thediagnosis of pneumonia [11]. In our study, only one radiologist was involved inoutlining the ROI area. In addition, the training data set is relatively small. Theperformance of this system is expected to increase when the training volume isincreased. It should also be noted that, the features of the CT images weanalyzed are from patients with severe lung lesions at later stages of diseasedevelopment. A study to associate this with the progress and all pathologicstages of COVID-19 is necessary to optimize the diagnostic system.In future, we intend to link hierarchical features of CT images to featuresof other factors such as genetic, epidemiological and clinical information formulti-omics and multi-modeling analysis for enhanced disease diagnosis. Theartificial intelligence systemdeveloped in our study could significantlycontribute to COVID-19 disease control by reducing the number of PUIs fortimely quarantine and treatment.and clinical features of the 2019 novel coronavirus outbreak in China.[2] Wang D, Hu B, Hu C, Zhu F, Liu X, Zhang J, et al. Clinical Characteristics of138 Hospitalized Patients With 2019 Novel Coronavirus-Infected Pneumoniain Wuhan, China. Jama 2020.[3] Chen N, Zhou M, Dong X, Qu J, Gong F, Han Y, et al. Epidemiological andclinical characteristics of 99 cases of 2019 novel coronavirus pneumonia inWuhan, China: a descriptive study. Lancet 2020.[4] Li Q, Guan X, Wu P, Wang X, Zhou L, Tong Y, et al. Early TransmissionDynamics in Wuhan, China, of Novel Coronavirus-Infected Pneumonia. TheNew England journal of medicine 2020.[5] Huang C, Wang Y, Li X, Ren L, Zhao J, Hu Y, et al. Clinical features ofpatients infected with 2019 novel coronavirus in Wuhan, China. Lancet 2020.surveillance : bulletin Europeen sur les maladies transmissibles = Europeancommunicable disease bulletin 2020;25.[7] Chu DKW, Pan Y, Cheng SMS, Hui KPY, Krishnan P, Liu Y, et al. MolecularDiagnosis of a Novel Coronavirus (2019-nCoV) Causing an Outbreak ofPneumonia. Clinical chemistry 2020.[8] Chung M, Bernheim A, Mei X, Zhang N, Huang M, Zeng X, et al. CTImaging Features of 2019 Novel Coronavirus (2019-nCoV). Radiology2020:200230.[9] Gomez P, Semmler M, Schutzenberger A, Bohr C, Dollinger M. Low-lightimage enhancement of high-speed endoscopic videos using a convolutionalneural network. Med Biol Eng Comput 2019;57:1451-63.[10] Choe J, Lee SM, Do KH, Lee G, Lee JG, Lee SM, et al. DeepLearning-based Image Conversion of CT Reconstruction Kernels ImprovesRadiomics Reproducibility for Pulmonary Nodules or Masses. Radiology2019;292:365-73.[11] Kermany DS, Goldbaum M, Cai W, Valentim CCS, Liang H, Baxter SL, etal. Identifying Medical Diagnoses and Treatable Diseases by Image-BasedDeep Learning. Cell 2018;172:1122-31 e9.[12] Negassi M, Suarez-Ibarrola R, Hein S, Miernik A, Reiterer A. Application ofartificial neural networks for automated analysis of cystoscopic images: areview of the current status and future prospects. World J Urol 2020.Development and validation of a deep-learning algorithm for the detection ofpolyps during colonoscopy. Nat Biomed Eng 2018;2:741-8.", "ref_list": [[], [""], ["Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR"], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], "ref_authors": [[], ["Y Yang", "Q Lu", "M Liu", "Y Wang", "A Zhang", "N Jalali", "VM Corman", "O Landt", "M Kaiser", "R Molenkamp", "A Meijer", "DK Chu"], ["P Wang", "X Xiao", "JR Glissen Brown", "TM Berzin", "M Tu", "F Xiong", "HJ Koo", "S Lim", "J Choe", "SH Choi", "H Sung", "KH Do"], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], "fir_para": "Bo Xu, MD, PhD\nThe authors have declared no competing interest.", "one_words_summarize": "Bo Xu, MD, PhDThe authors have declared no competing interest. Viral nucleic acid testing based onspecimens from the lower respiratory tract is the diagnostic gold standard. Based on COVID-19 radiographical changes in CT images, wehypothesized that Artificial Intelligence\u2019s deep learning methods might be able toextract COVID-19\u2019s specific graphical features and provide a clinical diagnosisahead of the pathogenic test, thus saving critical time for disease control. Also, CNN has been applied to identify the nature ofpulmonary nodules via CT images, the diagnosis of pediatric pneumonia viachest X-ray images, automated precising and labeling of polyps duringcolonoscopic videos, cystoscopic image recognition extraction from videos[10-13].There are a number of features for identifying viral pathogens on the basisof imaging patterns, which are associated with their specific pathogenesis [14].The hallmarks of COVID-19 are bilateral distribution of patchy shadows andground glass opacity [2]. We achieved a total accuracy of 83% with specificity of80.5% and sensitivity of 84% for validation. For a ROI, it is sized approximately from 395*223 to 636*533pixels. We reduced the dimension of features before it wassent to the final classification layer. In this study, we combined Decision tree and Adaboostto produce the performance. FP and FN mean thenumber of false positive false negative samples. Two radiologists were asked to review the images andsketched a total of 453 representative images (258 for COVID-19 negative and195 for COVID-19 positive) for analysis. These images were randomly dividedinto a training set and a validation set. The DL algorithm yielded an AUC of 0.90 (95% CI, 0.86 to 0.94 ) on theinternal validation and 0.78 (95% CI, 0.71 to 0.84) on the external validation. Moreover, the high performance of the deeplearning model we developed in this study was tested using external sampleswith 73% accuracy. Further developing this systemcan significantly shorten thediagnosis time for disease control. In addition, it can reduce the diagnosticworkload of physicians in the field. Our study represents the first study to applyartificial intelligence technologies to CT images for effectively screening forCOVID-19.The gold standard for COVID-19 diagnosis has been nucleic acid baseddetection for the existence of specific sequences of the SARS-COV-2 gene. In our study, only one radiologist was involved inoutlining the ROI area. It should also be noted that, the features of the CT images weanalyzed are from patients with severe lung lesions at later stages of diseasedevelopment. Jama 2020.[3] Chen N, Zhou M, Dong X, Qu J, Gong F, Han Y, et al. Early TransmissionDynamics in Wuhan, China, of Novel Coronavirus-Infected Pneumonia. TheNew England journal of medicine 2020.[5] Huang C, Wang Y, Li X, Ren L, Zhao J, Hu Y, et al. Clinical features ofpatients infected with 2019 novel coronavirus in Wuhan, China. Identifying Medical Diagnoses and Treatable Diseases by Image-BasedDeep Learning."}